#
# f32 <-> s32 <-> s8 <-> u8
#
--reset
--sdt=f32,s32,s8,u8
--ddt=f32,s32,s8,u8

--attr-scales=src:per_dim_1
--stag=abx,axb,aBx4b,aBx8b,aBx16b
--dtag=abx,axb,aBx8b,aBx16b
2x64x3x3

--stag=abx,axb,aBx16b
--dtag=abx,axb,aBx16b
--attr-scales=,src:per_dim_1
--attr-post-ops=sum:0.5
2x64x1x1

--attr-scales=src:per_dim_0
--stag=abx,xba
--dtag=abx,xba
2x64x3x3

--attr-scales=src:per_dim_01
--stag=abx,gOIhw16i16o
--dtag=abx,gOIhw16i16o
3x32x32x2x2

# blocked with tail
--stag=aBx4b,aBx8b --dtag=aBx16b 2x40x3x3
--stag=aBx16b      --dtag=aBx8b  2x40x3x3
--stag=ab --dtag=AB16b16a2b 16x63

--attr-scales=src:common:0.25
--stag=abx,axb
--dtag=abx,axb
2x8x8 # special 8x8 kernel

--stag=abx,axb,aBx4b,aBx8b,aBx16b
--dtag=abx,axb,aBx4b,aBx8b,aBx16b
2x64x3x3

--stag=abx,xba
--dtag=abx,xba
2x64x3x3

# Matmul blocked B layouts
--sdt=f32 --ddt=f32
--stag=ab,ba --dtag=BA16a16b,BA16a32b,BA16a48b,BA16a64b 89x73
--dtag=ab,ba --stag=BA16a16b,BA16a32b,BA16a48b,BA16a64b 89x73
--stag=abc,acb --dtag=aCB16b16c,aCB16b32c,aCB16b48c,aCB16b64c 57x89x73
--dtag=abc,acb --stag=aCB16b16c,aCB16b32c,aCB16b48c,aCB16b64c 57x89x73

# brdgmm layouts
--sdt=f32 --ddt=f32
--stag=axb --dtag=decbA8a 2x17x12x16x16 65x16x16x5x5

# simple nChw{8,16}c impl
--sdt=f32 --ddt=f32
--stag=aBx4b,aBx8b --dtag=aBx16b 2x71x16x16 2x72x16x16 2x73x16x16
--stag=aBx16b      --dtag=aBx8b  2x71x16x16 2x72x16x16 2x73x16x16

# test if jit kernels properly handle corner cases:
# * large stride problems
# * huge dimensions (UINT_MAX + 1)
--reset
--skip-impl=ref,simple # ! test jit version only
--sdt=f32 --ddt=f32
--stag=abx --dtag=aBx8b 2x16x19200x19200
--skip-impl=
1x4294967296x1

# f16
--batch=test_reorder_float16

# bf16
--batch=test_reorder_bfloat16

# fp8
--batch=test_reorder_float8

# Run-time
--batch=harness_reorder_runtime

# Saturation
--batch=harness_reorder_saturation

# Weights formats for AMX kernels
--batch=harness_reorder_amx

# Compensation
--batch=harness_reorder_compensation

# Regression
--batch=harness_reorder_regression

# Scales
--batch=harness_reorder_scales
