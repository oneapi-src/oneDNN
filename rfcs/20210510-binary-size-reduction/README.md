# oneDNN binary size reduction through build system.

## Problem Statement.
Some oneDNN customers, including the OpenVINO toolkit, have requirements for
their applications to fit a specific disk space quota. Currently, applications
linked statically with oneDNN exceed this quota a lot due to the library
implementation way. Our experiments show that binary size of statically linked
end-user application may take up to 64 MB [1]. Further analysis revealed
several spots that contribute most:

* The implementation of threading layer through templates. This is TBB specific,
  OMP doesn't suffer from it. Takes ~14 MB. Update: was resolved in v2.4,
  decreasing the top level of disk space to 50 MB for [1].
* The implementation of reorders through templates of plain C code and their
  multiple instantiations. Takes ~9 MB.
* The implementation of GEMM autogenerated JIT-ted kernels. Takes ~14 MB.
* The implementation of convolution kernels apart from GEMM. Takes ~8 MB.
* Rest functionality takes ~12 MB + ~2 MB of core API.

### Updated disk space chart
Current breakdown for future v2.4 release for disk space of certain parts:

* ~2 MB for core API.
* ~12 MB for core compute functionality: convolution, deconvolution, inner
  product and matmul.
* ~14 MB is GEMM auto-generated kernels (would be part of compute unless
  replaced)
* ~11 MB are reorders (~10 MB are instances of simple reorders which could be
  replaced with jit-ted one)
* ~11 MB is the rest functionality.

## Background
The reason why static linking can't solve the problem itself is the way library
API is implemented. The call to `dnnl_primitive_desc_create` (which is also used
underneath the correspondent C++ API) relies on statically defined
implementation lists which contain all primitives at once. That means that if
user calls the function (which is an essential part of the API), they get the
full library in their application. And there are not many choices how to deal
with such problem. One is to switch off implementations in compile time (this
RFC proposal) or using a different API which would separate things on different
levels (at least on primitive one).

## Proposal
To control the size the proposal is to utilize the power of build system and
let the user specify a set of desired functionality. The proposal targets
sources modifications without changing API or any API availability despite
user choices.

The idea is to have sets of macros, one is external and would be defined by the
build system based on user choices. This external set would control another set
- internal - which lives inside the library and modifies implementation lists.
Each primitive would get several macros to switch on/off certain implementations
during compilation time. Further optimizations of disk space will be provided by
linker which excludes unused code inside the end-user application unless certain
scenario happens [2].

The proposal is to introduce three new build options which would define the list
of available implementations for user at build time:
* DNNL_ENABLE_WORKLOAD. This option supports two values: TRAINING (the default)
  and INFERENCE. Second one is a subset of first one and strips backward off.
* DNNL_ENABLE_PRIMITIVE. This option supports all primitive names as they are
  used in the library API. E.g. `-DDNNL_ENABLE_PRIMITIVE=CONVOLUTION;REORDER`.
  Anything that is not listed explicitly will be excluded from lists.
  Enumeration comes with semicolon as a standard CMake string delimiter.

This list may be extended in future upon request if it's proven to help with
further size reduction with minimal amount of enabling efforts and maintenance
cost.

Pros:
1. No API changes and transparent enabling on user side.
2. Simple enabling inside the library once infrastructure is set up.

Cons:
1. Relies on code structure and requires code modification to be most effective.
   See [2].
2. May require complicated validation and can't be fully covered as there are
   enormous number of combinations to build and run.

There is also an ISA extension RFC [here](ISA_extension.md).

## Additional Comments
[1] oneDNN v2.2 + gcc 4.8.5 + release mode + standard linker +
    TBB threading (2017.2) + c++11 + native optimizations on AVX2.

[2] Certain scenario mentioned is the following. Assume linker uses
implementation list as the primary entry point to fill the binary with
implementations code. It needs to include all code into the binary which was
referenced from the list. It finds object files (that is, translation units) and
includes necessary code and may include some unnecessary code too. Unnecessary
code can be either of:
* Instantiations of non-requested templated classes.
* Specializations of non-requested templated classes or class members.
* Non-templated definitions of non-requested classes.

Non-requested classes refer mostly to backward propagation kind related codes
and their auxiliary methods. It also refers to ISA-specific instantiations
which were explicitly disabled by a user. This linker behavior can't be changed
or influenced externally.

## Implementation Details

Build system will define the following set of macros:

```cpp
// Primitives list controls
// Propagation kind controls
#cmakedefine01 BUILD_TRAINING
#cmakedefine01 BUILD_INFERENCE
// Primitives controls
#cmakedefine01 BUILD_PRIMITIVE_ALL
#cmakedefine01 BUILD_BATCH_NORMALIZATION
#cmakedefine01 BUILD_BINARY
...
```

Based on this `BUILD_XXX` macros, the following internal macros would be set:

```cpp
// src/common/impl_registration.hpp (new header):

#if BUILD_PRIMITIVE_ALL || (BUILD_CONVOLUTION)
#define REG_CONV_FWD(...) __VA_ARGS__
#else
#define REG_CONV_FWD(...)
#endif

#if BUILD_PRIMITIVE_ALL || (BUILD_CONVOLUTION && BUILD_TRAINING)
#define REG_CONV_BWD_D(...) __VA_ARGS__
#define REG_CONV_BWD_W(...) __VA_ARGS__
#else
#define REG_CONV_BWD_D(...)
#define REG_CONV_BWD_W(...)
#endif
```

`BWD_D` and `BWD_W` separation applies for convolution only to handle
deconvolution dependency gracefully. Rest would receive simply `BWD` despite the
fact they may support data and weights separately.

Finally, these internal macros are applied inside primitive implementation
lists:

```cpp
// src/cpu/cpu_convolution_list.cpp:
const std::map<conv_impl_key_t, std::vector<pd_create_f>> impl_list_map {
    // FWD fp
    {{forward, f32, f32, f32}, {
        REG_CONV_FWD(REG_IP_FWD(CPU_INSTANCE_X64(ip_convolution_fwd_t)))
        REG_CONV_FWD(CPU_INSTANCE_X64(brgemm_1x1_convolution_fwd_t<avx512_core>))
        ...
        CPU_INSTANCE_AARCH64_ACL(acl_wino_convolution_fwd_t)
        CPU_INSTANCE_AARCH64(jit_sve_512_dw_convolution_fwd_t)
        ...
        REG_CONV_FWD(CPU_INSTANCE(gemm_convolution_fwd_t))
        REG_CONV_FWD(CPU_INSTANCE(ref_convolution_fwd_t))
        REG_CONV_FWD(CPU_INSTANCE(ref_fused_convolution_fwd_t))
        nullptr,
    }},
```

Aarch64 implementations wouldn't be a part of change in the first part of
changes.

To resolve unnecessary code inclusions, it is enough to physically separate,
i.e., by propagation kind, forward implementation details from backward into
different translation units. Since non-requested implementations would disappear
from the implementation list, linker won't use structures not instantiated in
the list and their method bodies defined in different translation units from
requested ones. This is likely not the cheapest but straightforward solution
which allows to leave the code almost intact.

All nested primitives calling should be handled internally by the library. User
wouldn't be responsible to handle internal dependencies.

Implementation details are subject to change and only for educational purposes
here to shed a light on a mechanism.

## Testing
Some ideas for testing. It's likely to be covered internally and may be covered
in Weekly cycles to replace existing build with builds for specific primitives
and run them the way they are running now. This way we keep the testing scope
but also validate partial build feature. E.g., for convolutions build would
require to specify `-DDNNL_ENABLE_PRIMITIVE=CONVOLUTION;REORDER` and this should
be enough to successfully run all test_benchdnn_conv_xxx targets.

EOD.
